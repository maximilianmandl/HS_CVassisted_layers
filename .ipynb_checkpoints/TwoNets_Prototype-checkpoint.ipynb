{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tf\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Image Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "###Functions \n",
    "\n",
    "def splitter(dataset,split=(70,15,15),seed=None):\n",
    "\n",
    "    assert sum(split)==100\n",
    "\n",
    "    dataset_length = len(dataset)\n",
    "    \n",
    "    if seed != None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    train_data = []\n",
    "    valid_data = []\n",
    "    test_data = []\n",
    "        \n",
    "    for i in range(0,len(dataset)):\n",
    "      \n",
    "        chance = np.random.randint(0,100)\n",
    "\n",
    "        if chance < split[0]:\n",
    "            train_data.append(dataset[i,])\n",
    "            \n",
    "        elif chance >= split[0] and chance < (split[0]+split[1]):\n",
    "            valid_data.append(dataset[i,])\n",
    "        \n",
    "        elif chance >= (split[0]+split[1]) and chance < sum(split): \n",
    "            test_data.append(dataset[i,])\n",
    "            \n",
    "        else: \n",
    "            print(chance)\n",
    "  \n",
    "    return np.array(train_data), np.array(valid_data), np.array(test_data)\n",
    "        \n",
    "    \n",
    "def showRandomSamples(dataset,path='DATA/Images/destination/',seed=42):\n",
    "    \n",
    "    pick = np.random.randint(0,len(dataset),size=1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    #ax = fig.subplots(1,4)\n",
    "    \n",
    "    #for i,i_img in enumerate(pick):\n",
    "        \n",
    "     #   ax = fig.add_subplot(1,1,(i+1))\n",
    "    img = dataset[pick]['image']\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    return none\n",
    "\n",
    "def dynDevice():\n",
    "    if torch.cuda.device_count() == 0:\n",
    "        device = 'cpu'\n",
    "    elif torch.cuda.device_count() > 0:\n",
    "        device = 'cuda'\n",
    "        nDevice = torch.cuda.device_count()  #setup for later implementation of multi gpu parallel processing\n",
    "    return device\n",
    "\n",
    "print(dynDevice())\n",
    "\n",
    "  \n",
    "def inv_normalize(x):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16896\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Unusable</th>\n",
       "      <th>Moderately good</th>\n",
       "      <th>Good-number of layers</th>\n",
       "      <th>quality</th>\n",
       "      <th>cats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Garth_A01_G006_0001[0,0].jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Garth_A01_G006_0001[0,1].jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Garth_A01_G006_0001[0,2].jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Garth_A01_G006_0001[0,3].jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Garth_A01_G006_0001[0,4].jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File Name  Unusable  Moderately good  \\\n",
       "0  Garth_A01_G006_0001[0,0].jpg       1.0              NaN   \n",
       "1  Garth_A01_G006_0001[0,1].jpg       1.0              NaN   \n",
       "2  Garth_A01_G006_0001[0,2].jpg       1.0              NaN   \n",
       "3  Garth_A01_G006_0001[0,3].jpg       1.0              NaN   \n",
       "4  Garth_A01_G006_0001[0,4].jpg       1.0              NaN   \n",
       "\n",
       "   Good-number of layers  quality cats  \n",
       "0                    NaN        0  bad  \n",
       "1                    NaN        0  bad  \n",
       "2                    NaN        0  bad  \n",
       "3                    NaN        0  bad  \n",
       "4                    NaN        0  bad  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.read_csv('Garth_ML_index.csv')\n",
    "#annotations_good.drop(['Unusable', 'Moderately good'], axis=1, inplace=True)\n",
    "quality = np.array(np.zeros(len(annotations),dtype=np.int32))\n",
    "\n",
    "for i in range(0,len(quality)):\n",
    "    if not np.isnan(annotations['Unusable'][i]):\n",
    "        quality[i]=0\n",
    "    elif not np.isnan(annotations['Moderately good'][i]):\n",
    "        quality[i]= 1\n",
    "    elif not np.isnan(annotations['Good-number of layers'][i]):\n",
    "        quality[i] = 2\n",
    "\n",
    "def cats(x):\n",
    "    if x == 0:\n",
    "        return 'bad'\n",
    "    if x == 1:\n",
    "        return 'mediocre'\n",
    "    if x == 2:\n",
    "        return 'good'\n",
    "    \n",
    "annotations_class = annotations.copy()\n",
    "annotations_class['quality'] = quality\n",
    "annotations_class['cats'] = annotations_class['quality'].apply(cats)\n",
    "annotations_class['cats'] = annotations_class['cats'].astype('category')\n",
    "\n",
    "print(len(annotations_class))\n",
    "\n",
    "annotations_class.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(annotations_class['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bad', 'good', 'mediocre'], dtype='object')\n",
      "2153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Unusable</th>\n",
       "      <th>Moderately good</th>\n",
       "      <th>Good-number of layers</th>\n",
       "      <th>quality</th>\n",
       "      <th>cats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Garth_A01_G006_0001[7,5].jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Garth_A01_G006_0002[0,7].jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Garth_A01_G006_0002[1,2].jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Garth_A01_G006_0002[1,3].jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Garth_A01_G006_0002[1,6].jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       File Name  Unusable  Moderately good  \\\n",
       "61  Garth_A01_G006_0001[7,5].jpg       NaN              NaN   \n",
       "71  Garth_A01_G006_0002[0,7].jpg       NaN              NaN   \n",
       "74  Garth_A01_G006_0002[1,2].jpg       NaN              NaN   \n",
       "75  Garth_A01_G006_0002[1,3].jpg       NaN              NaN   \n",
       "78  Garth_A01_G006_0002[1,6].jpg       NaN              NaN   \n",
       "\n",
       "    Good-number of layers  quality  cats  \n",
       "61                    3.0        2  good  \n",
       "71                    4.0        2  good  \n",
       "74                    3.0        2  good  \n",
       "75                    3.0        2  good  \n",
       "78                    3.0        2  good  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(annotations_class['cats'].cat.categories)\n",
    "annotations_class_good = annotations_class[annotations_class['quality']==2]\n",
    "\n",
    "print(len(annotations_class_good))\n",
    "\n",
    "annotations_class_good.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
      "    (4): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# class TwoModelA(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "        \n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = torch.nn.Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.conv2 = torch.nn.Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.conv3 = torch.nn.Conv2d(6, 9, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.fc1 = torch.nn.Linear(in_features=28*28*9, out_features=512, bias=True)\n",
    "#         self.fc2 = torch.nn.Linear(in_features=512, out_features=128, bias=True)\n",
    "#         self.fc3 = torch.nn.Linear(in_features=128, out_features=3, bias=True)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "#     def forward(self,x):\n",
    "        \n",
    "#         x = F.elu(self.conv1(x))\n",
    "#         x = F.elu(self.conv2(F.dropout(F.max_pool2d(x,kernel_size=2,stride=2),p=0.2)))\n",
    "#         x = F.elu(self.conv3(F.dropout(F.max_pool2d(x,kernel_size=2,stride=2),p=0.2)))\n",
    "#         x = F.max_pool2d(x,kernel_size=2,stride=2).view(-1,28*28*9)\n",
    "#         x = F.elu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(F.dropout(x,p=0.2)))\n",
    "#         x = self.fc3(F.dropout(x,p=0.2))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# modelA =TwoModelA()\n",
    "\n",
    "# print(modelA)\n",
    "\n",
    "# total=0\n",
    "# for param in modelA.parameters():\n",
    "#     total+=param.numel()\n",
    "#     print(param.numel())\n",
    "\n",
    "# print('________________')\n",
    "# print(total)\n",
    "\n",
    "\n",
    "# criterionA = torch.nn.CrossEntropyLoss() \n",
    "# optimizerA = torch.optim.AdamW(modelA.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=True)\n",
    "\n",
    "\n",
    "\n",
    "modelA = models.resnet18(pretrained=False)\n",
    "#for param in alexnet.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "modelA.conv1 = torch.nn.Conv2d(1, 64,kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modelA.fc = torch.nn.Sequential(torch.nn.Linear(512, 512), #ALTERNATIVELY w ORdered Dic: nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)),('', nn.),...]))\n",
    "                                 torch.nn.ReLU(),\n",
    "                                 torch.nn.Dropout(0.5),\n",
    "                                 torch.nn.Linear(512, 3),\n",
    "                                 torch.nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterionA = torch.nn.NLLLoss()\n",
    "optimizerA = torch.optim.AdamW(modelA.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=True)\n",
    "\n",
    "print(modelA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# class TwoModelB(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "        \n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = torch.nn.Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.conv2 = torch.nn.Conv2d(6, 9, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.conv3 = torch.nn.Conv2d(9, 12, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.fc1 = torch.nn.Linear(in_features=28*28*12, out_features=512, bias=True)\n",
    "#         self.fc2 = torch.nn.Linear(in_features=512, out_features=128, bias=True)\n",
    "#         self.fc3 = torch.nn.Linear(in_features=128, out_features=1, bias=True)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "#     def forward(self,x):\n",
    "        \n",
    "#         x = F.elu(self.conv1(x))\n",
    "#         x = F.elu(self.conv2(F.dropout(F.max_pool2d(x,kernel_size=2,stride=2),p=0.2)))\n",
    "#         x = F.elu(self.conv3(F.dropout(F.max_pool2d(x,kernel_size=2,stride=2),p=0.2)))\n",
    "#         x = F.max_pool2d(x,kernel_size=2,stride=2).view(-1,28*28*12)\n",
    "#         x = F.elu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(F.dropout(x,p=0.2)))\n",
    "#         x = self.fc3(F.dropout(x,p=0.2))\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# modelB = TwoModelB()\n",
    "\n",
    "# print(modelB)\n",
    "\n",
    "# total=0\n",
    "# for param in modelB.parameters():\n",
    "#     total+=param.numel()\n",
    "#     print(param.numel())\n",
    "\n",
    "# print('________________')\n",
    "# print(total)\n",
    "\n",
    "# criterionB = torch.nn.SmoothL1Loss()\n",
    "# optimizerB = torch.optim.AdamW(modelB.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=True)\n",
    "\n",
    "modelB = models.resnet18(pretrained=False)\n",
    "#for param in alexnet.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "print(modelB)\n",
    "\n",
    "modelA.conv1 = torch.nn.Conv2d(1, 64,kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "modelB.fc = torch.nn.Sequential(torch.nn.Linear(512, 512), #ALTERNATIVELY w ORdered Dic: nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)),('', nn.),...]))\n",
    "                                 torch.nn.ReLU(),\n",
    "                                 torch.nn.Dropout(0.4),\n",
    "                                 torch.nn.Linear(512, 1))\n",
    "\n",
    "criterionB = torch.nn.SmoothL1Loss()\n",
    "optimizerB = torch.optim.AdamW(modelB.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=True)\n",
    "\n",
    "print(modelB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((256-4)/2-4)/2-4)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Custom Data Loader\n",
    "\n",
    "class customDs(Dataset):\n",
    "    \n",
    "    def __init__(self,dataset, mode,path = 'DATA/Images/destination/', transforms=None):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.mode = mode #quality or layers\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "      \n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        image = Image.open(self.path+self.dataset[idx][0]).getchannel('G')\n",
    "        quality =self.dataset[idx][4]\n",
    "        \n",
    "       \n",
    "        \n",
    "        ##Encode for ML##\n",
    "        \n",
    "        if self.transforms!=None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        if self.mode == 'quality':\n",
    "            sample = (image,quality)\n",
    "    \n",
    "        elif self.mode =='layers':\n",
    "            assert quality==2, 'Dataset contains images of bad quality; training will fail'\n",
    "            n_layers = self.dataset[idx][3] if not np.isnan(self.dataset[idx][3]) else self.dataset[idx][2] if not np.isnan(self.dataset[idx][2]) else 0\n",
    "            sample = (image,n_layers) \n",
    "\n",
    "        else:\n",
    "            print('mode unknown; only accepts \"quality\" or \"layers\"')\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'DATA/Images/destinations/'\n",
    "img = Image.open('DATA/Images/destination/Garth_A01_G006_0220[0,1].jpg').getchannel('G')\n",
    "plt.imshow(img)\n",
    "np.array(img)\n",
    "\n",
    "#img = torch.tensor(img)\n",
    "#comp = make_grid(torch.stack([img,img,img]))\n",
    "#plt.imshow(np.transpose(comp.numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img.convert('L'))\n",
    "# np.array(img.convert('L'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-valid-test split = 70%, 15%, 15%\n",
    "np.random.seed(42)\n",
    "ann_trainA, ann_validA, ann_testA = splitter(annotations_class.values,(70,15,15))\n",
    "ann_trainB, ann_validB, ann_testB = splitter(annotations_class_good.values,(70,15,15))\n",
    "\n",
    "print(len(ann_trainA),len(ann_trainB))\n",
    "print(len(ann_validA),len(ann_validB))\n",
    "print(len(ann_testA),len(ann_testB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_trainDs = customDs(ann_trainA,mode = 'quality',transforms=tf.Compose([\n",
    "#                                               tf.Grayscale(num_output_channels=1),\n",
    "                                               tf.RandomHorizontalFlip(p=0.5),\n",
    "                                               tf.RandomVerticalFlip(p=0.5),\n",
    "                                               tf.RandomPerspective(distortion_scale=0.05, p=0.10, interpolation=3),\n",
    "                                               tf.RandomRotation(degrees=90, resample=False, expand=False, center=None),\n",
    "                                               tf.Resize((256,256), interpolation=2),\n",
    "                                               tf.ToTensor(),\n",
    "#                                               tf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "\n",
    "                          \n",
    "\n",
    "tf_validDs = customDs(ann_validA,mode = 'quality',transforms=tf.Compose([\n",
    "#                                               tf.Grayscale(num_output_channels=1),\n",
    "                               #                tf.RandomHorizontalFlip(p=0.5),\n",
    "                               #                tf.RandomVerticalFlip(p=0.5),\n",
    "                               #                tf.RandomPerspective(distortion_scale=0.1, p=0.1, interpolation=3),\n",
    "                               #                tf.RandomRotation(degrees=20, resample=False, expand=False, center=None),\n",
    "                                               tf.Resize((256,256), interpolation=2),\n",
    "                                               tf.ToTensor(),\n",
    "#                                               tf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "\n",
    "tf_testDs = customDs(ann_testA,mode = 'quality',transforms=tf.Compose([\n",
    "#                                               tf.Grayscale(num_output_channels=1),\n",
    "                                #               tf.RandomHorizontalFlip(p=0.5),\n",
    "                                #               tf.RandomVerticalFlip(p=0.5),\n",
    "                                #               tf.RandomPerspective(distortion_scale=0.1, p=0.1, interpolation=3),\n",
    "                                #               tf.RandomRotation(degrees=20, resample=False, expand=False, center=None),\n",
    "                                               tf.Resize((256,256), interpolation=2),\n",
    "                                               tf.ToTensor(),\n",
    "#                                               tf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "\n",
    "\n",
    "batchSize = 4\n",
    "train_loader = DataLoader(tf_trainDs, batch_size = batchSize, pin_memory=True, drop_last=True,shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(tf_validDs, batch_size = batchSize, pin_memory=False, drop_last=True, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(tf_testDs, batch_size = batchSize, pin_memory=False, drop_last=True, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "    break\n",
    "    \n",
    "im = make_grid(img,nrow=4)\n",
    "plt.figure(figsize=(12,12))\n",
    "print(label)\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "modelA.to(device = dynDevice())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs = 1\n",
    "# training_losses = []\n",
    "# validation_losses = []\n",
    "# training_accuracies = []\n",
    "# validation_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(0,epochs): \n",
    "    \n",
    "#     epoch_start = time.time()\n",
    "#     i=0\n",
    "#     losses=0\n",
    "#     accuracies=0\n",
    "\n",
    "#     modelA.train()\n",
    "#     for img, label in train_loader:\n",
    "#         i+=1\n",
    "#         img, label = img.to(device = dynDevice()), label.to(device = dynDevice())\n",
    "#         result = modelA(img)\n",
    "#         loss = criterionA(result,label)\n",
    "#         losses+=loss.item()\n",
    "        \n",
    "#         #Accuracies: is the quality well constrained? if so, are the layers correctly determined? \n",
    "#         accuracies+= (result.argmax(dim=1) == label).sum().item()        \n",
    "\n",
    "#    #     if i%500 ==0:\n",
    "#    #         print(f'Training BATCH:{i}   LOSS:{loss.item()}   ACCURACY:{accuracies[0]/i}')\n",
    "#    #         break\n",
    "        \n",
    "        \n",
    "#         #Update Model\n",
    "#         optimizerA.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizerA.step()\n",
    "       \n",
    "#     training_losses.append(losses/i) \n",
    "#     training_accuracies.append(accuracies/(i*batchSize))\n",
    "#     training_end =time.time()\n",
    "\n",
    "#     #Validate\n",
    "#     i=0\n",
    "#     losses=0\n",
    "#     accuracies=0\n",
    "#     modelA.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for img, label in valid_loader:\n",
    "#             i+=1\n",
    "#             img, label = img.to(device = dynDevice()), label.to(device = dynDevice())\n",
    "#             result = modelA(img)\n",
    "#             loss = criterionA(result,label)\n",
    "#             losses+=loss.item()\n",
    "#             accuracies+= (result.argmax(dim=1) == label).sum().item()        \n",
    "\n",
    "\n",
    "        \n",
    "#         validation_losses.append(losses/i)   \n",
    "#         validation_accuracies.append(accuracies/(i*batchSize))\n",
    "#         validation_end = time.time()\n",
    "    \n",
    "#     print(f'The epoch took {(validation_end-epoch_start):.0f}s. \\n    training took {(training_end-epoch_start):.0f}s \\n    validation took {(validation_end-training_end):.0f}s')\n",
    "\n",
    "#     print(f'Losses were \\n    training loss: {training_losses[-1]:.3f} \\n    validation loss: {validation_losses[-1]:.3f}')\n",
    "    \n",
    "#     print(f'Accuracies were \\n    training accuracy: {training_accuracies[-1]:.3f} \\n    validation accuracy: {validation_accuracies[-1]:.3f}\\n\\n\\n\\n\\n')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 42\n",
    "#epochs=10\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "for j in range(0,epochs): \n",
    "    \n",
    "    epoch_start = time.time()\n",
    "    i=0\n",
    "    losses=0\n",
    "    accuracies=0\n",
    "\n",
    "    modelA.train()\n",
    "    for img, label in train_loader:\n",
    "        i+=1\n",
    "        img, label = img.to(device = dynDevice()), label.to(device = dynDevice())\n",
    "        result = modelA.forward(img)\n",
    "        loss = criterionA(result,label)\n",
    "        losses+=loss.item()\n",
    "        \n",
    "        #Accuracies: is the quality well constrained? if so, are the layers correctly determined? \n",
    "        accuracies+= (result.argmax(dim=1) == label).sum().item()        \n",
    "       \n",
    "        #Update Model\n",
    "        optimizerA.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizerA.step()\n",
    "       \n",
    "    training_losses.append(losses/i) \n",
    "    training_accuracies.append(accuracies/(i*batchSize))\n",
    "    training_end =time.time()\n",
    "\n",
    "    #Validate\n",
    "    i=0\n",
    "    losses=0\n",
    "    accuracies=0\n",
    "    modelA.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, label in valid_loader:\n",
    "            i+=1\n",
    "            img, label = img.to(device = dynDevice()), label.to(device = dynDevice())\n",
    "            result = modelA.forward(img)\n",
    "            loss = criterionA(result,label)\n",
    "            losses+=loss.item()\n",
    "            accuracies+= (result.argmax(dim=1) == label).sum().item()        \n",
    "#            if i%100 ==0:\n",
    "#                print(f'Validation BATCH:{i}   LOSS:{loss.item()}   ACCURACY:{accuracies/(i*batchSize)}')\n",
    "#                break\n",
    "\n",
    "        \n",
    "        validation_losses.append(losses/i)   \n",
    "        validation_accuracies.append(accuracies/(i*batchSize))\n",
    "        validation_end = time.time()\n",
    "    \n",
    "    print(f'The {j}th epoch took {(validation_end-epoch_start):.0f}s. \\n    training took {(training_end-epoch_start):.0f}s \\n    validation took {(validation_end-training_end):.0f}s')\n",
    "\n",
    "    print(f'Losses were \\n    training loss: {training_losses[-1]:.3f} \\n    validation loss: {validation_losses[-1]:.3f}')\n",
    "    \n",
    "    print(f'Accuracies were \\n    training accuracy: {training_accuracies[-1]:.3f} \\n    validation accuracy: {validation_accuracies[-1]:.3f}\\n\\n\\n\\n\\n')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result\n",
    "except:\n",
    "    pass\n",
    "\n",
    "torch.save(obj=modelA,f='modelA_bw_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='training losses')\n",
    "plt.plot(validation_losses,label='validation losses')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_trainDs = customDs(ann_trainB,mode = 'layers',transforms=tf.Compose([\n",
    "                                         #      tf.Grayscale(num_output_channels=1),\n",
    "                                               tf.RandomHorizontalFlip(p=0.5),\n",
    "                                               tf.RandomVerticalFlip(p=0.5),\n",
    "                                               tf.RandomPerspective(distortion_scale=0.05, p=0.10, interpolation=3),\n",
    "                                               tf.RandomRotation(degrees=90, resample=False, expand=False, center=None),\n",
    "                                               tf.Resize((256,256), interpolation=2),\n",
    "                                               tf.ToTensor(),\n",
    "#                                               tf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "\n",
    "                          \n",
    "\n",
    "tf_validDs = customDs(ann_validB,mode = 'layers',transforms=tf.Compose([\n",
    "                                 #              tf.Grayscale(num_output_channels=1),\n",
    "                               #                tf.RandomHorizontalFlip(p=0.5),\n",
    "                               #                tf.RandomVerticalFlip(p=0.5),\n",
    "                               #                tf.RandomPerspective(distortion_scale=0.1, p=0.1, interpolation=3),\n",
    "                               #                tf.RandomRotation(degrees=20, resample=False, expand=False, center=None),\n",
    "                                               tf.Resize((256,256), interpolation=2),\n",
    "                                               tf.ToTensor(),\n",
    "#                                               tf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "\n",
    "tf_testDs = customDs(ann_testB,mode = 'layers',transforms=tf.Compose([\n",
    "                                    #           tf.Grayscale(num_output_channels=1),\n",
    "                                #               tf.RandomHorizontalFlip(p=0.5),\n",
    "                                #               tf.RandomVerticalFlip(p=0.5),\n",
    "                                #               tf.RandomPerspective(distortion_scale=0.1, p=0.1, interpolation=3),\n",
    "                                #               tf.RandomRotation(degrees=20, resample=False, expand=False, center=None),\n",
    "                                               tf.Resize((256,256), interpolation=2),\n",
    "                                               tf.ToTensor(),\n",
    "#                                               tf.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "\n",
    "\n",
    "batchSize = 4\n",
    "train_loader = DataLoader(tf_trainDs, batch_size = batchSize, pin_memory=True, drop_last=True,shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(tf_validDs, batch_size = batchSize, pin_memory=True, drop_last=True, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(tf_testDs, batch_size = batchSize, pin_memory=True, drop_last=True, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "    break\n",
    "    \n",
    "im = make_grid(img,nrow=12)\n",
    "plt.figure(figsize=(12,4))\n",
    "print(label)\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "modelB.to(device = dynDevice())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "#epochs=100\n",
    "\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "for j in range(0,epochs): \n",
    "    \n",
    "    epoch_start = time.time()\n",
    "    i=0\n",
    "    losses=0\n",
    "    accuracies=0\n",
    "\n",
    "    modelB.train()\n",
    "    for img, label in train_loader:\n",
    "        i+=1\n",
    "        img, label = img.to(device = dynDevice()), label.to(device = dynDevice(), dtype=torch.float32)\n",
    "        result = modelB(img)\n",
    "        loss = criterionB(result,label.view(-1,1))\n",
    "        losses+=loss.item()\n",
    "        \n",
    "        #Accuracies: is the quality well constrained? if so, are the layers correctly determined? \n",
    "        accuracies+= (result.detach().cpu().numpy().flatten().round() == label.detach().cpu().numpy().round()).sum()        \n",
    "\n",
    "#        if i%100 ==0:\n",
    "#            print(f'Training BATCH:{i}   LOSS:{loss.item()}   ACCURACY:{accuracies/i}')\n",
    "#            break\n",
    "        \n",
    "        \n",
    "        #Update Model\n",
    "        optimizerB.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizerB.step()\n",
    "        \n",
    "\n",
    "  \n",
    "        \n",
    "    training_losses.append(losses/i) \n",
    "    training_accuracies.append(accuracies/(i*batchSize))\n",
    "    training_end =time.time()\n",
    "\n",
    "    #Validate\n",
    "    i=0\n",
    "    losses=0\n",
    "    accuracies=[0,0,0]\n",
    "    modelB.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, label in valid_loader:\n",
    "            i+=1\n",
    "            img, label = img.to(device = dynDevice()), label.to(device = dynDevice(),dtype=torch.float32)\n",
    "            result = modelB(img)\n",
    "            loss = criterionB(result,label.view(-1,1))\n",
    "            losses+=loss.item()\n",
    "            accuracies[0]+= (result.detach().cpu().numpy().flatten().round() == label.detach().cpu().numpy().round()).sum()\n",
    "            accuracies[1]+= (result.detach().cpu().numpy().flatten().round() == (label.detach().cpu().numpy().round())-1).sum()\n",
    "            accuracies[2]+= (result.detach().cpu().numpy().flatten().round() == (label.detach().cpu().numpy().round())+1).sum()\n",
    "            \n",
    "            \n",
    "            \n",
    "#            if i%100 ==0:\n",
    "#                print(f'Training BATCH:{i}   LOSS:{loss.item()}   ACCURACY:{accuracies/i}')\n",
    "#                break\n",
    "\n",
    "        \n",
    "        validation_losses.append(losses/i)   \n",
    "        validation_accuracies.append(np.array(accuracies)/(i*batchSize))\n",
    "        validation_end = time.time()\n",
    "    \n",
    "    print(f'The {j}th epoch took {(validation_end-epoch_start):.0f}s. \\n    training took {(training_end-epoch_start):.0f}s \\n    validation took {(validation_end-training_end):.0f}s')\n",
    "\n",
    "    print(f'Losses were \\n    training loss: {training_losses[-1]:.3f} \\n    validation loss: {validation_losses[-1]:.3f}')\n",
    "    \n",
    "    print(f'Accuracies were \\n    training accuracy: {training_accuracies[-1]:.3f} \\n    validation accuracy: {validation_accuracies[-1][0]:.3f}')\n",
    "    \n",
    "    print(f'Accuracies were \\n    underestimated by 1 layer: {validation_accuracies[-1][1]:.3f} \\n    overestimated by 1 layer: {validation_accuracies[-1][2]:.3f}\\n\\n\\n\\n')\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='training losses')\n",
    "plt.plot(validation_losses,label='validation losses')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.detach().cpu().numpy().round()+10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=modelB,f='modelB_bw_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
