{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tf\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = torch.load('MODELS/modelA_bw_resnet18_withTL.pth',map_location=torch.device('cuda:0'))\n",
    "modelB = torch.load('MODELS/modelB_bw_resnet18_withTL.pth',map_location=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "    (4): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(modelA)\n",
    "print(modelB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_core = cv2.imread('../Machine Learning_GARTH/Garth_base_oriented.jpg')\n",
    "#full_core = cv2.cvtColor(full_core,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "samples = ['Gulda_top_of_mid_orientedv2']\n",
    "zooms=[0.25,0.5,1,2,4,8]\n",
    "\n",
    "trans = tf.Compose([tf.Resize((256,256)),\n",
    "                  tf.ToTensor(),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice the Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed in the image and collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 4408 pixels,width: 24862 pixels\n",
      "images in height: 4,images in width: 24\n",
      "lost pixels in height: 312, lost pixels in width: 286\n",
      "0%\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "   \n",
    "    for zoom in zooms:   \n",
    "   \n",
    "        full_core = Image.open(f'../Machine Learning_GARTH/201012_jpgs/{sample}.jpg')\n",
    "        if len(full_core.getbands())>1:\n",
    "            full_core = np.array(Image.open(f'../Machine Learning_GARTH/201012_jpgs/{sample}.jpg').getchannel('G'))\n",
    "        else:\n",
    "            full_core = np.array(Image.open(f'../Machine Learning_GARTH/201012_jpgs/{sample}.jpg'))\n",
    "\n",
    "\n",
    "        h_in = int(256/zoom)\n",
    "        w_in = h_in\n",
    "\n",
    "        h = full_core.shape[0]\n",
    "        w = full_core.shape[1]\n",
    "\n",
    "        n_h = h//h_in\n",
    "        n_w = w//w_in\n",
    "\n",
    "        r_h = h%h_in\n",
    "        r_w = w%w_in\n",
    "\n",
    "        print(f'height: {h} pixels,width: {w} pixels')\n",
    "        print(f'images in height: {n_h},images in width: {n_w}')\n",
    "        print(f'lost pixels in height: {r_h}, lost pixels in width: {r_w}')\n",
    "\n",
    "\n",
    "\n",
    "        full_core = full_core[int(round(r_h/2)):(h-int(round(r_h/2))),int(round(r_w/2)):(w-int(round(r_w/2)))]\n",
    "\n",
    "        quality_matrix = np.zeros((n_h,n_w), dtype = int) \n",
    "        layer_matrix = np.zeros((n_h,n_w), dtype = float)\n",
    "\n",
    "        w_point = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for j in range(n_w):\n",
    "            try:\n",
    "                if j%int(n_w/10) ==0:\n",
    "                    print(f'{j//int(n_w/10)*10:.0F}%')\n",
    "            except:\n",
    "                pass\n",
    "            h_point = 0\n",
    "            for i in range(n_h):        \n",
    "                active_image = full_core[h_point:h_point+h_in,w_point:w_point+w_in]\n",
    "                active_image = Image.fromarray(active_image)\n",
    "\n",
    "                h_point+=h_in\n",
    "\n",
    "                quality_matrix[i,j] =  modelA(trans(active_image).view(1,1,256,256).cuda()).argmax(dim=1).item()\n",
    "\n",
    "                if quality_matrix[i,j]!=0:\n",
    "                    layer_matrix[i,j] =  modelB(trans(active_image).view(1,1,256,256).cuda()).item()\n",
    "\n",
    "            w_point+=w_in\n",
    "\n",
    "        print(time.time()-start_time)\n",
    "\n",
    "        #save model\n",
    "\n",
    "        tosave = pd.DataFrame(layer_matrix)\n",
    "        tosave.head()\n",
    "        tosave.to_csv(f'{sample}_{zoom}.csv',index=False, header=True)\n",
    "\n",
    "\n",
    "        #load model\n",
    "        toload=pd.read_csv(f'{sample}_{zoom}.csv')\n",
    "        layer_matrix1 = toload.to_numpy()\n",
    "        layer_matrix= layer_matrix1\n",
    "\n",
    "        full_core_density_bin = np.zeros((full_core.shape[0],full_core.shape[1]), dtype = float)\n",
    "\n",
    "        for j in range(full_core_density_bin.shape[1]):\n",
    "            for i in range(full_core_density_bin.shape[0]):\n",
    "                full_core_density_bin[i,j]=layer_matrix[(i-1)//h_in,(j-1)//w_in]\n",
    "\n",
    "            if j%int(full_core_density_bin.shape[1]/10)==0:\n",
    "                print(f'{j/int(full_core_density_bin.shape[1])*100:.0F}%')\n",
    "\n",
    "        fig,(ax1,ax2,ax3) = plt.subplots(nrows=3,ncols=1, sharex=False)\n",
    "\n",
    "        im = ax2.imshow(full_core_density_bin,cmap='hot')\n",
    "        fig.colorbar(im, ax = ax3, orientation='horizontal')\n",
    "\n",
    "        #ax1.set_xticklabels()\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(15)\n",
    "        ax1.imshow(full_core, cmap='gray')\n",
    "        ax1.set_yticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax1.set_xticks(np.round(np.linspace(0,full_core.shape[1],10)))\n",
    "        #ax1.set_xticklabels(np.linspace(0,24251,10,dtype=int))\n",
    "\n",
    "        ax2.set_xticks(np.round(np.linspace(0,full_core.shape[1],10)))\n",
    "        #ax2.set_xticklabels(np.linspace(0,24251,10,dtype=int))\n",
    "        ax2.set_xlabel('position in sample (in pixels)')\n",
    "        ax3.imshow(np.zeros([1,full_core.shape[1]]))\n",
    "        ax3.set_yticks([])\n",
    "        ax3.set_xticks([])\n",
    "        ax3.set_xticklabels([])\n",
    "        ax3.set_axis_off()\n",
    "\n",
    "        stamp = time.strftime(\"%Y%m%d%H%M%S\", time.gmtime())\n",
    "\n",
    "        plt.savefig('core_layerDensity_{}_{}_{}.png'.format(sample,zoom, str(stamp)))\n",
    "\n",
    "\n",
    "        carlo = []\n",
    "        layer_reduced=[]\n",
    "        sd=[]\n",
    "        sem=[]\n",
    "        avg=[]\n",
    "        n=[]\n",
    "        missing_len=0\n",
    "        missing_tot=0\n",
    "\n",
    "        for j in range(layer_matrix.shape[1]-1):\n",
    "\n",
    "\n",
    "            popul = layer_matrix[:,j][layer_matrix[:,j]!=0]\n",
    "           # try: \n",
    "            layer_reduced.append(popul)\n",
    "            if popul.size == 0:\n",
    "                missing_len+=1\n",
    "            else:\n",
    "                missing_tot+=popul.size\n",
    "\n",
    "           # except:\n",
    "           #     layer_reduced.append(100000)\n",
    "           #     print(10000000000000000)\n",
    "\n",
    "            try:\n",
    "                sd.append(np.std(popul))       \n",
    "            except:\n",
    "                sd.append(0)\n",
    "            try:\n",
    "                avg.append(np.mean(popul))\n",
    "            except:\n",
    "                avg.append(0)\n",
    "\n",
    "\n",
    "            try:    \n",
    "                n.append(popul.size)\n",
    "            except:\n",
    "                n.append(0)\n",
    "\n",
    "            try:\n",
    "                sem.append(np.std(popul)/np.sqrt(popul.size))\n",
    "            except:\n",
    "                sem.append(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sd.append(0)\n",
    "        sem.append(0)\n",
    "        avg.append(0)\n",
    "        n.append(0)\n",
    "\n",
    "        missing_len = missing_len/n_w*100\n",
    "        missing_tot = 1-(missing_tot/(n_w*n_h))\n",
    "\n",
    "\n",
    "        for i in range(10000):\n",
    "\n",
    "            if i%1000 ==0:\n",
    "                print(f'{i//1000*10:.0F}%')\n",
    "\n",
    "            carlo_count = 0\n",
    "            for popul in layer_reduced:\n",
    "    #            popul = layer_matrix[:,j][layer_matrix[:,j]!=0]\n",
    "    #            popul = layer_matrix[:,j]\n",
    "\n",
    "                try:\n",
    "                    carlo_count += np.random.choice(popul,1,replace=False).item()\n",
    "                except:\n",
    "                    pass\n",
    "            carlo.append(carlo_count)\n",
    "\n",
    "        minimum_carlo = round(min(carlo))\n",
    "        maximum_carlo = round(max(carlo))\n",
    "        avg_carlo = round(statistics.mean(carlo))\n",
    "        med_carlo = round(statistics.median(carlo))\n",
    "        sd_carlo=round(statistics.stdev(carlo))\n",
    "        stepsize_carlo = int((maximum_carlo-minimum_carlo)/20) if int((maximum_carlo-minimum_carlo)/20)>0 else 1\n",
    "\n",
    "\n",
    "        fig,(ax1) = plt.subplots(nrows=1,ncols=1, sharex=False)\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "        ax1.hist(carlo,bins=(range(minimum_carlo,maximum_carlo+stepsize_carlo,stepsize_carlo)))\n",
    "        ax1.axvline(avg_carlo, color='k', linestyle='dashed', linewidth=1)\n",
    "        ax1.text(avg_carlo+stepsize_carlo, stepsize_carlo, 'Mean: {:.2f}'.format(avg_carlo))\n",
    "\n",
    "        ax1.set_xlabel('n total layers in sample')\n",
    "        ax1.set_ylabel('count of Monte Carlo (10000)')\n",
    "        ylim=ax1.get_ylim()[1]*1.5\n",
    "        ax1.set_ylim(0,ylim)\n",
    "\n",
    "        ax1.text(minimum_carlo-stepsize_carlo/4,ylim*0.70,f'''Number of recombinations: 10,000\n",
    "        Sample Name: {sample}\n",
    "        Zoom: {zoom}x\n",
    "        unconstrained sample:{missing_tot:.1F}%\n",
    "        unconstrained length of sample:{missing_len:.1F}%\n",
    "        Minimmun number of layers: {minimum_carlo}\n",
    "        Maximum number of layers: {maximum_carlo}\n",
    "        Average number of layers:{avg_carlo}\n",
    "        Median number of layers: {med_carlo}\n",
    "        SD of the simulation: {sd_carlo}''')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        stamp = time.strftime(\"%Y%m%d%H%M%S\", time.gmtime())\n",
    "\n",
    "        plt.savefig('monte_carlo_{}_{}_{}.png'.format(sample, zoom, str(stamp)))\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
